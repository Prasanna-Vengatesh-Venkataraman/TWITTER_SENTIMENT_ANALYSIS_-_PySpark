{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Pras\n",
      "[nltk_data]     Vengs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install nltk\n",
    "import tweepy as tw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br>STEP 1 - Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing Twitter API credentials which are stored in a csv file\n",
    "twitter_creds = pd.read_csv(\"Twitter Creds.csv\", index_col=0)\n",
    "\n",
    "access_token = twitter_creds.loc[\"ACCESS_TOKEN\"][0]\n",
    "access_secret = twitter_creds.loc[\"ACCESS_SECRET\"][0]\n",
    "consumer_key = twitter_creds.loc[\"CONSUMER_KEY\"][0]\n",
    "consumer_secret = twitter_creds.loc[\"CONSUMER_SECRET\"][0]\n",
    "\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "api = tw.API(auth)\n",
    "\n",
    "# New dataframe to store the tweets and username \n",
    "df = pd.DataFrame(columns = ['Tweets', 'User'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br>STEP 2 - Apache Spark Streaming Application on Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for spark  stream to collect the data\n",
    "def stream(data, file_name):\n",
    "    i = 0\n",
    "    for tweet in tw.Cursor(api.search, q=data, count=1000, lang='en').items():\n",
    "        print(i+1, end='\\r')\n",
    "        df.loc[i, 'Tweets'] = tweet.text\n",
    "        df.loc[i, 'User'] = tweet.user.name\n",
    "        df.to_excel('{}.xlsx'.format(file_name))\n",
    "        i+=1\n",
    "        if i == 1000:\n",
    "            break\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\r"
     ]
    }
   ],
   "source": [
    "stream(data = ['#hospital'], file_name = 'my_tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove @tags and URL(s) in the tweets\n",
    "def clean_tweet(tweet):\n",
    "    return ' '.join(re.sub('(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)', ' ', tweet).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>User</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @NewsRajwar: The adept #team of #doctors to...</td>\n",
       "      <td>Ajay Kadian</td>\n",
       "      <td>rt the adept team of doctors to include the re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You don't have to go to the #hospital if you h...</td>\n",
       "      <td>Corey Schoenrock</td>\n",
       "      <td>you don t have to go to the hospital if you ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Healthcare Executive wishes everyone a very Ha...</td>\n",
       "      <td>Healthcare Executive</td>\n",
       "      <td>healthcare executive wishes everyone a very ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@narendramodi Please provide #Hospital for hum...</td>\n",
       "      <td>Kuldeep Saharan Sandol</td>\n",
       "      <td>please provide hospital for human in every vil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Texas governor requests use of El Paso-area #...</td>\n",
       "      <td>USA Customers</td>\n",
       "      <td>texas governor requests use of el paso area mi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets                    User  \\\n",
       "0  RT @NewsRajwar: The adept #team of #doctors to...             Ajay Kadian   \n",
       "1  You don't have to go to the #hospital if you h...        Corey Schoenrock   \n",
       "2  Healthcare Executive wishes everyone a very Ha...    Healthcare Executive   \n",
       "3  @narendramodi Please provide #Hospital for hum...  Kuldeep Saharan Sandol   \n",
       "4  #Texas governor requests use of El Paso-area #...           USA Customers   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  rt the adept team of doctors to include the re...  \n",
       "1  you don t have to go to the hospital if you ha...  \n",
       "2  healthcare executive wishes everyone a very ha...  \n",
       "3  please provide hospital for human in every vil...  \n",
       "4  texas governor requests use of el paso area mi...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing cleaned tweets in a new column in the Data Frame\n",
    "df['clean_tweet'] = df['Tweets'].apply(lambda x: clean_tweet(x))\n",
    "df['clean_tweet'] = df['clean_tweet'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br>STEP 3 - Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 positive words: ['a+', 'abound', 'abounds', 'abundance', 'abundant', 'accessable', 'accessible', 'acclaim', 'acclaimed', 'acclamation'] \n",
      "\n",
      "First 10 negative words: ['2-faced', '2-faces', 'abnormal', 'abolish', 'abominable', 'abominably', 'abominate', 'abomination', 'abort', 'aborted']\n"
     ]
    }
   ],
   "source": [
    "# Reading the negative-words text file\n",
    "with open(\"negative-words.txt\",\"r\") as file:\n",
    "        neg_list = file.readlines()\n",
    "\n",
    "negative_words=[]\n",
    "\n",
    "for i in range(len(neg_list)):\n",
    "    negative_words.append(neg_list[i].split(\"\\n\")[0])\n",
    "    \n",
    "\n",
    "# Reading the positive-words text  file\n",
    "with open(\"positive-words.txt\",\"r\") as file:\n",
    "        pos_list = file.readlines()\n",
    "\n",
    "positive_words=[]\n",
    "\n",
    "for i in range(len(pos_list)):\n",
    "    positive_words.append(pos_list[i].split(\"\\n\")[0])\n",
    "    \n",
    "print(\"First 10 positive words:\",positive_words[:10],\"\\n\\nFirst 10 negative words:\",negative_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the sentiment score for a single tweet\n",
    "def tweet_sentiment_value(tweet):\n",
    "\n",
    "    # Initializing Sentiment value to zero\n",
    "    sentiment_value=0\n",
    "    \n",
    "    # Using  nltk.toeknize to split the tweet into individual words\n",
    "    for word in nltk.word_tokenize(tweet):\n",
    "        \n",
    "        # If word is in positive list increment sentiment value by 1\n",
    "        if word in positive_words:\n",
    "            sentiment_value+=1\n",
    "        \n",
    "        # If word is in Negative list decrease sentiment value by 1\n",
    "        elif word in negative_words:\n",
    "            sentiment_value-=1\n",
    "    \n",
    "    # Return the final sentiment score of the tweet\n",
    "    return sentiment_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br><br><center>Sentiment Analysis with SPARK dataframe</center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required packages and initiating a spark session\n",
    "import findspark\n",
    "import pyspark\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import desc\n",
    "from collections import namedtuple\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "findspark.init('C:\\Spark\\spark-3.0.1-bin-hadoop2.7')\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a spark Dataframe\n",
    "dfspark = spark.createDataFrame(df)\n",
    "dfspark = dfspark.dropna()\n",
    "dfspark.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|              Tweets|                User|         clean_tweet|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|RT @NewsRajwar: T...|         Ajay Kadian|rt the adept team...|\n",
      "|You don't have to...|    Corey Schoenrock|you don t have to...|\n",
      "|Healthcare Execut...|Healthcare Executive|healthcare execut...|\n",
      "|@narendramodi Ple...|Kuldeep Saharan S...|please provide ho...|\n",
      "|#Texas governor r...|       USA Customers|texas governor re...|\n",
      "|RT @NeilFlochMD: ...|Rafael Alba Alifo...|rt many hospital ...|\n",
      "|RT @NeilFlochMD: ...|       Neil Floch MD|rt many hospital ...|\n",
      "|@ASlavitt Many #H...|       Neil Floch MD|many hospital sys...|\n",
      "|Good Morning ! â...|Wish Fertility Ho...|good morning new ...|\n",
      "|DC G'bl conducts ...|      Rising Kashmir|dc g bl conducts ...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Displaying first 10 rows of  Spark DataFrame\n",
    "dfspark.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_content</th>\n",
       "      <th>Sentiment score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @NewsRajwar: The adept #team of #doctors to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You don't have to go to the #hospital if you h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Healthcare Executive wishes everyone a very Ha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@narendramodi Please provide #Hospital for hum...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Texas governor requests use of El Paso-area #...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Tweet_content  Sentiment score\n",
       "0  RT @NewsRajwar: The adept #team of #doctors to...                0\n",
       "1  You don't have to go to the #hospital if you h...                0\n",
       "2  Healthcare Executive wishes everyone a very Ha...                1\n",
       "3  @narendramodi Please provide #Hospital for hum...                0\n",
       "4  #Texas governor requests use of El Paso-area #...                0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List to score sentiment value of each tweet\n",
    "sentiment_score = []\n",
    "\n",
    "# Iterating \"clean_tweet\" column of Spark dataframe and passing each tweet thorugh \"tweet_sentiment_value\" function\n",
    "for tweets in dfspark.select('clean_tweet').collect():\n",
    "    #Storing the sentiment score in \"sentiment_score\" list \n",
    "    sentiment_score.append(tweet_sentiment_value(tweets[0]))\n",
    "    \n",
    "# Creating a  dataframe with original tweets and their corresponding sentiment score\n",
    "df2 = pd.DataFrame({\"Tweet_content\":list(df[\"Tweets\"]) , \"Sentiment score\":sentiment_score})\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br>Step 4 - Exporting the sentiment scores to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"Final Output.csv\",  index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
